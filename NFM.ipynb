{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ejiVlGYHe1c",
        "outputId": "3eb8e001-a272-4695-8066-80c623f92c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=nltk.corpus.stopwords.words('english')\n",
        "new_stopwords = ['movie','movies','film','love','good','like','best','great','ring','shawshank','films','one','ive','watch','thing']\n",
        "stop_words.extend(new_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr-0PgdKObmL",
        "outputId": "8e44be9e-1e6d-4f3e-8514-e51232385ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/csv_files/reviews.csv', on_bad_lines='skip')\n",
        "df=pd.DataFrame(data)\n",
        "reviews=data[['review.text']]\n",
        "\n",
        "def clean_text(review):\n",
        "  le=WordNetLemmatizer()\n",
        "  word_tokens=word_tokenize(review)\n",
        "  tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
        "  cleaned_text=\" \".join(tokens)\n",
        "  return cleaned_text\n",
        "\n",
        "df['cleaned_review']=df['review.text'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "CSxTRPJ9NSFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1500, min_df=10, stop_words=stop_words)\n",
        "X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "words = np.array(vectorizer.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_npH35vNs8x",
        "outputId": "83dd0bb2-686a-4ae2-e9c9-3f1ddc82de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 822)\t0.05975148630737792\n",
            "  (0, 64)\t0.10326235239479861\n",
            "  (0, 498)\t0.0901312243498474\n",
            "  (0, 510)\t0.0924909771573494\n",
            "  (0, 332)\t0.07335083019421428\n",
            "  (0, 43)\t0.054964353379337694\n",
            "  (0, 11)\t0.05113929363639745\n",
            "  (0, 1259)\t0.102081085394891\n",
            "  (0, 375)\t0.09106289876635483\n",
            "  (0, 1093)\t0.10015936677329344\n",
            "  (0, 488)\t0.09243866989303412\n",
            "  (0, 528)\t0.08539868701468993\n",
            "  (0, 1096)\t0.06772134364137483\n",
            "  (0, 408)\t0.05904721201981099\n",
            "  (0, 538)\t0.07353589623110472\n",
            "  (0, 949)\t0.07655260333691656\n",
            "  (0, 344)\t0.07425577955183575\n",
            "  (0, 12)\t0.05611557442568483\n",
            "  (0, 838)\t0.08416428759569157\n",
            "  (0, 202)\t0.07199348354411181\n",
            "  (0, 100)\t0.07219329943205599\n",
            "  (0, 1279)\t0.07365774511294598\n",
            "  (0, 1203)\t0.06140008273532719\n",
            "  (0, 251)\t0.17880225822805568\n",
            "  (0, 434)\t0.06824331795647942\n",
            "  :\t:\n",
            "  (69902, 404)\t0.2409037260525802\n",
            "  (69903, 1030)\t0.6213620580343118\n",
            "  (69903, 441)\t0.47386024960743245\n",
            "  (69903, 440)\t0.4193408079862761\n",
            "  (69903, 964)\t0.3031216789242202\n",
            "  (69903, 1474)\t0.3487638043159371\n",
            "  (69904, 1196)\t0.4124096706276125\n",
            "  (69904, 103)\t0.4278758138608599\n",
            "  (69904, 172)\t0.4086925948059516\n",
            "  (69904, 316)\t0.4352642139722392\n",
            "  (69904, 43)\t0.2671484620122399\n",
            "  (69904, 100)\t0.35088794327767037\n",
            "  (69904, 1146)\t0.2249770950353246\n",
            "  (69904, 404)\t0.21272196804271498\n",
            "  (69905, 288)\t0.5035644864039817\n",
            "  (69905, 879)\t0.5124288059218605\n",
            "  (69905, 709)\t0.44855785772502005\n",
            "  (69905, 537)\t0.31843264945655386\n",
            "  (69905, 765)\t0.31063893840921947\n",
            "  (69905, 800)\t0.2911004515135689\n",
            "  (69906, 1022)\t0.5133700537554006\n",
            "  (69906, 4)\t0.5151906038256171\n",
            "  (69906, 681)\t0.5142491039610242\n",
            "  (69906, 1314)\t0.3548068640106779\n",
            "  (69906, 1330)\t0.2840594620201289\n",
            "*****************************\n",
            "X =  ['aaron' 'ability' 'able' ... 'young' 'youre' 'youve']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nmf = NMF(n_components=10, solver=\"mu\")\n",
        "W = nmf.fit_transform(X)\n",
        "H = nmf.components_\n",
        "\n",
        "for i, topic in enumerate(H):\n",
        "     print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in words[topic.argsort()[-10:]]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnbBvxCBNBYw",
        "outputId": "d2a58653-6ef4-4362-a7e2-851a4269658b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: even,would,much,dont,people,well,think,see,really,story\n",
            "Topic 2: christopher,begins,bale,nolan,ledger,heath,knight,dark,joker,batman\n",
            "Topic 3: perfect,far,masterpiece,never,simply,havent,greatest,made,seen,ever\n",
            "Topic 4: two,books,fellowship,read,jackson,peter,book,trilogy,lord,rings\n",
            "Topic 5: seen,never,still,watching,years,saw,many,first,times,watched\n",
            "Topic 6: story,favourite,top,perfect,first,masterpiece,every,favorite,greatest,time\n",
            "Topic 7: red,tim,hope,morgan,robbins,freeman,life,andy,redemption,prison\n",
            "Topic 8: marlon,mafia,vito,brando,michael,part,pacino,corleone,family,godfather\n",
            "Topic 9: durden,tyler,david,fincher,edward,norton,brad,pitt,club,fight\n",
            "Topic 10: job,heath,absolutely,performance,everything,cast,really,actors,acting,amazing\n"
          ]
        }
      ]
    }
  ]
}