{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ejiVlGYHe1c",
        "outputId": "3eb8e001-a272-4695-8066-80c623f92c1b"
      },
      "source": [
        "#Author: Oğuzhan Öztürk to get contact: oguzhanozturk0@outlook.com\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=nltk.corpus.stopwords.words('english')\n",
        "new_stopwords = ['movie','movies','film','love','good','like','best','great','ring','shawshank','films','one','ive','watch','thing']\n",
        "stop_words.extend(new_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr-0PgdKObmL",
        "outputId": "8e44be9e-1e6d-4f3e-8514-e51232385ea6"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSxTRPJ9NSFo"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('CSV FILE PATH', on_bad_lines='skip')\n",
        "df=pd.DataFrame(data)\n",
        "reviews=data[['review.text']]\n",
        "\n",
        "def clean_text(review):\n",
        "  le=WordNetLemmatizer()\n",
        "  word_tokens=word_tokenize(review)\n",
        "  tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
        "  cleaned_text=\" \".join(tokens)\n",
        "  return cleaned_text\n",
        "\n",
        "df['cleaned_review']=df['review.text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_npH35vNs8x",
        "outputId": "83dd0bb2-686a-4ae2-e9c9-3f1ddc82de6d"
      },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1500, min_df=10, stop_words=stop_words)\n",
        "X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "words = np.array(vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnbBvxCBNBYw",
        "outputId": "d2a58653-6ef4-4362-a7e2-851a4269658b"
      },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 1: even,would,much,dont,people,well,think,see,really,story\n",
            "Topic 2: christopher,begins,bale,nolan,ledger,heath,knight,dark,joker,batman\n",
            "Topic 3: perfect,far,masterpiece,never,simply,havent,greatest,made,seen,ever\n",
            "Topic 4: two,books,fellowship,read,jackson,peter,book,trilogy,lord,rings\n",
            "Topic 5: seen,never,still,watching,years,saw,many,first,times,watched\n",
            "Topic 6: story,favourite,top,perfect,first,masterpiece,every,favorite,greatest,time\n",
            "Topic 7: red,tim,hope,morgan,robbins,freeman,life,andy,redemption,prison\n",
            "Topic 8: marlon,mafia,vito,brando,michael,part,pacino,corleone,family,godfather\n",
            "Topic 9: durden,tyler,david,fincher,edward,norton,brad,pitt,club,fight\n",
            "Topic 10: job,heath,absolutely,performance,everything,cast,really,actors,acting,amazing\n"
          ]
        }
      ],
      "source": [
        "nmf = NMF(n_components=10, solver=\"mu\")\n",
        "W = nmf.fit_transform(X)\n",
        "H = nmf.components_\n",
        "\n",
        "for i, topic in enumerate(H):\n",
        "     print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in words[topic.argsort()[-10:]]])))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
